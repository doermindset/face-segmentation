{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:50:13.790424900Z",
     "start_time": "2024-01-12T16:50:08.776134100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from data.lfw_dataset import LFWDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from metrics.segmentation_metrics import compute_metrics\n",
    "from models.uNet import UNet\n",
    "from tqdm import tqdm\n",
    "from model_checkpoint import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "step = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:50:21.242230500Z",
     "start_time": "2024-01-12T16:50:21.232217Z"
    }
   },
   "id": "8246e28a1190864c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    mean_accuracy, mean_iou, mean_fw_iou = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in tqdm(enumerate(test_loader), desc=\"evaluate_unet\"):\n",
    "            imgs = data[\"image\"]\n",
    "            segs = data[\"seg\"]\n",
    "            imgs, segs = imgs.to(device), segs.to(device)\n",
    "\n",
    "            segs_pred = model(imgs)\n",
    "\n",
    "            mpa, m_iou = compute_metrics(segs, segs_pred)\n",
    "            mean_accuracy.append(mpa)\n",
    "            mean_iou.append(m_iou)\n",
    "\n",
    "    wandb.log({\"Test Mean Pixel Acc\": np.mean(mean_accuracy), \"Test Mean IoU\": np.mean(mean_iou)}, step=step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:50:38.483787800Z",
     "start_time": "2024-01-12T16:50:38.407252500Z"
    }
   },
   "id": "654f946af4a4638e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def val(model, val_loader, criterion, config, device, epoch):\n",
    "    global step\n",
    "    running_loss = 0.0\n",
    "    mean_accuracy, mean_iou, mean_fw_iou = [], [], []\n",
    "    table = wandb.Table(columns=[\"id\", \"image\", \"pred\", \"gt\"])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(enumerate(val_loader, 0),\n",
    "                unit=' images',\n",
    "                unit_scale=config.batch_size,\n",
    "                total=len(val_loader),\n",
    "                smoothing=0,\n",
    "                disable=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (batch_idx, data) in pbar:\n",
    "            imgs = data[\"image\"]\n",
    "            segs = data[\"seg\"]\n",
    "            imgs, segs = imgs.to(device), segs.to(device)\n",
    "\n",
    "            segs_pred = model(imgs)\n",
    "            loss = criterion(segs_pred, segs)\n",
    "\n",
    "            if batch_idx < 5:\n",
    "                table.add_data(\n",
    "                    *[f'{step}_{batch_idx}', wandb.Image(imgs[0]), wandb.Image(segs_pred[0]), wandb.Image(segs[0])])\n",
    "\n",
    "            running_loss += float(loss)\n",
    "            val_loss = float(running_loss) / (batch_idx + 1)\n",
    "\n",
    "            pbar.set_description(f'Validation [ E {epoch}, L {loss}, L_Avg {val_loss}')\n",
    "\n",
    "            mpa, m_iou = compute_metrics(segs, segs_pred)\n",
    "            mean_accuracy.append(mpa)\n",
    "            mean_iou.append(m_iou)\n",
    "\n",
    "        val_loss = float(running_loss) / len(val_loader)\n",
    "\n",
    "        wandb.log({\"Validation Loss\": val_loss,\n",
    "                   \"Validation Mean Pixel Acc\": np.mean(mean_accuracy),\n",
    "                   \"Validation Mean IoU\": np.mean(mean_iou)}, step=step)\n",
    "\n",
    "        wandb.log({\"Images Data\": table})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:50:50.350709300Z",
     "start_time": "2024-01-12T16:50:50.186160700Z"
    }
   },
   "id": "96ed1fbe18e30cec"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, config, device, epoch):\n",
    "    running_loss = 0.0\n",
    "    global step\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_loader, 0),\n",
    "                unit=' images',\n",
    "                unit_scale=config.batch_size,\n",
    "                total=len(train_loader),\n",
    "                smoothing=0,\n",
    "                disable=False)\n",
    "\n",
    "    for (batch_idx, data) in pbar:\n",
    "\n",
    "        imgs = data[\"image\"]\n",
    "        segs = data[\"seg\"]\n",
    "        imgs, segs = imgs.to(device), segs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        segs_pred = model(imgs)\n",
    "        loss = criterion(segs_pred, segs)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += float(loss)\n",
    "        step += len(imgs)\n",
    "        train_loss = float(running_loss) / (batch_idx + 1)\n",
    "        pbar.set_description(f'Training [ E {epoch}, L {loss}, L_Avg {train_loss}')\n",
    "\n",
    "        batch_idx += 1\n",
    "        if batch_idx % config.log_freq == 0:\n",
    "            wandb.log({\"Training Loss\": train_loss}, step=step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:51:01.649445200Z",
     "start_time": "2024-01-12T16:51:01.633431Z"
    }
   },
   "id": "74af0ed1c1b9968b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(config=hyperparameters):\n",
    "        config = wandb.config\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        train_dataset = LFWDataset(download=False, base_folder='lfw_dataset', split_name=\"train\")\n",
    "        val_dataset = LFWDataset(download=False, base_folder='lfw_dataset', split_name=\"val\")\n",
    "        test_dataset = LFWDataset(download=False, base_folder='lfw_dataset', split_name=\"test\")\n",
    "\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=config.batch_size,\n",
    "                                  pin_memory=True,\n",
    "                                  shuffle=False,\n",
    "                                  sampler=None,\n",
    "                                  num_workers=0)\n",
    "\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=config.batch_size,\n",
    "                                pin_memory=True,\n",
    "                                shuffle=False,\n",
    "                                sampler=None,\n",
    "                                num_workers=0)\n",
    "\n",
    "        test_loader = DataLoader(test_dataset,\n",
    "                                 batch_size=config.batch_size,\n",
    "                                 pin_memory=True,\n",
    "                                 shuffle=False,\n",
    "                                 sampler=None,\n",
    "                                 num_workers=0)\n",
    "\n",
    "        model = UNet(n_channels=3, n_classes=3)\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        for epoch in range(config.epochs):\n",
    "            val(model, val_loader, criterion, config, device, epoch)\n",
    "            train(model, train_loader, criterion, optimizer, config, device, epoch)\n",
    "\n",
    "        test(model, test_loader, device)\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:51:16.748928200Z",
     "start_time": "2024-01-12T16:51:16.728921200Z"
    }
   },
   "id": "5efeeaada48b70db"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mraul-stefan-pop\u001B[0m (\u001B[33mcvdl-3\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\work\\an 3\\dl\\face-segmentation\\wandb\\run-20240112_185143-noo67bp7</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/cvdl-3/pytorch-demo/runs/noo67bp7' target=\"_blank\">rich-valley-78</a></strong> to <a href='https://wandb.ai/cvdl-3/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/cvdl-3/pytorch-demo' target=\"_blank\">https://wandb.ai/cvdl-3/pytorch-demo</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/cvdl-3/pytorch-demo/runs/noo67bp7' target=\"_blank\">https://wandb.ai/cvdl-3/pytorch-demo/runs/noo67bp7</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation [ E 0, L 1.09744131565094, L_Avg 1.098200469777204:  93%|█████████▎| 552/592 [00:20<00:01, 26.81 images/s]   \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rauls\\AppData\\Local\\Temp\\ipykernel_24300\\1437673174.py\", line 39, in model_pipeline\n",
      "    val(model, val_loader, criterion, config, device, epoch, model_checkpoint)\n",
      "  File \"C:\\Users\\rauls\\AppData\\Local\\Temp\\ipykernel_24300\\4112474701.py\", line 29, in val\n",
      "    running_loss += float(loss)\n",
      "                    ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3964bb4d298f42479c1e544bd5d11495"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">rich-valley-78</strong> at: <a href='https://wandb.ai/cvdl-3/pytorch-demo/runs/noo67bp7' target=\"_blank\">https://wandb.ai/cvdl-3/pytorch-demo/runs/noo67bp7</a><br/> View job at <a href='https://wandb.ai/cvdl-3/pytorch-demo/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTcwNjQwMQ==/version_details/v0' target=\"_blank\">https://wandb.ai/cvdl-3/pytorch-demo/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTcwNjQwMQ==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20240112_185143-noo67bp7\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 10\u001B[0m\n\u001B[0;32m      1\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m      2\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m,\n\u001B[0;32m      3\u001B[0m     classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m     architecture\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUNet\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      8\u001B[0m     log_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m model_pipeline(config)\n",
      "Cell \u001B[1;32mIn[6], line 39\u001B[0m, in \u001B[0;36mmodel_pipeline\u001B[1;34m(hyperparameters)\u001B[0m\n\u001B[0;32m     37\u001B[0m model_checkpoint \u001B[38;5;241m=\u001B[39m ModelCheckpoint(\u001B[38;5;241m0.0\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_iou\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(config\u001B[38;5;241m.\u001B[39mepochs):\n\u001B[1;32m---> 39\u001B[0m     val(model, val_loader, criterion, config, device, epoch, model_checkpoint)\n\u001B[0;32m     40\u001B[0m     train(model, train_loader, criterion, optimizer, config, device, epoch)\n\u001B[0;32m     42\u001B[0m test(model, test_loader, device)\n",
      "Cell \u001B[1;32mIn[4], line 29\u001B[0m, in \u001B[0;36mval\u001B[1;34m(model, val_loader, criterion, config, device, epoch, model_ckpt)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_idx \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m5\u001B[39m:\n\u001B[0;32m     26\u001B[0m     table\u001B[38;5;241m.\u001B[39madd_data(\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;241m*\u001B[39m[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_idx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, wandb\u001B[38;5;241m.\u001B[39mImage(imgs[\u001B[38;5;241m0\u001B[39m]), wandb\u001B[38;5;241m.\u001B[39mImage(segs_pred[\u001B[38;5;241m0\u001B[39m]), wandb\u001B[38;5;241m.\u001B[39mImage(segs[\u001B[38;5;241m0\u001B[39m])])\n\u001B[1;32m---> 29\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(loss)\n\u001B[0;32m     30\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(running_loss) \u001B[38;5;241m/\u001B[39m (batch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     32\u001B[0m pbar\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation [ E \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, L \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, L_Avg \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "wandb.agent(\"654zaa5i\", model_pipeline, count=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T16:52:14.618551100Z",
     "start_time": "2024-01-12T16:51:40.938855300Z"
    }
   },
   "id": "187eca6685079695"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
