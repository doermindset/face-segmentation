{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/doermindset/face-segmentation.git\n",
    "%cd face-segmentation\n",
    "!git checkout develop\n",
    "%mkdir checkpoints"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4426cedae31d3f62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install wandb -Uq"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0214e90b271e6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from data.lfw_dataset import LFWDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from metrics.segmentation_metrics import compute_metrics\n",
    "from models.uNet import UNet\n",
    "from tqdm import tqdm\n",
    "from model_checkpoint import ModelCheckpoint\n",
    "\n",
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8246e28a1190864c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    mean_accuracy, mean_iou, mean_fw_iou = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in tqdm(enumerate(test_loader), desc=\"evaluate_unet\"):\n",
    "            imgs = data[\"image\"]\n",
    "            segs = data[\"seg\"]\n",
    "            imgs, segs = imgs.to(device), segs.to(device)\n",
    "\n",
    "            segs_pred = model(imgs)\n",
    "\n",
    "            mpa, m_iou, m_fw_iou = compute_metrics(segs, segs_pred)\n",
    "            mean_accuracy.append(mpa)\n",
    "            mean_iou.append(m_iou)\n",
    "            mean_fw_iou.append(m_fw_iou)\n",
    "\n",
    "    wandb.log({\"Test Mean Pixel Acc\": np.mean(mean_accuracy),\n",
    "               \"Test Mean IoU\": np.mean(mean_iou),\n",
    "               \"Test Frequency Weighted IoU\": np.mean(mean_fw_iou)}, step=step)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "654f946af4a4638e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def val(model, val_loader, criterion, config, device, epoch, model_ckpt):\n",
    "    global step\n",
    "    running_loss = 0.0\n",
    "    mean_accuracy, mean_iou, mean_fw_iou = [], [], []\n",
    "    table = wandb.Table(columns=[\"id\", \"image\", \"pred\", \"gt\"])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(enumerate(val_loader, 0),\n",
    "                unit=' images',\n",
    "                unit_scale=config.batch_size,\n",
    "                total=len(val_loader),\n",
    "                smoothing=0,\n",
    "                disable=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (batch_idx, data) in pbar:\n",
    "            imgs = data[\"image\"]\n",
    "            segs = data[\"seg\"]\n",
    "            imgs, segs = imgs.to(device), segs.to(device)\n",
    "\n",
    "            segs_pred = model(imgs)\n",
    "            loss = criterion(segs_pred, segs)\n",
    "\n",
    "            if batch_idx < 5:\n",
    "                table.add_data(\n",
    "                    *[f'{step}_{batch_idx}', wandb.Image(imgs[0]), wandb.Image(segs_pred[0]), wandb.Image(segs[0])])\n",
    "\n",
    "            running_loss += float(loss)\n",
    "            val_loss = float(running_loss) / (batch_idx + 1)\n",
    "\n",
    "            pbar.set_description(f'Validation [ E {epoch}, L {loss}, L_Avg {val_loss}')\n",
    "\n",
    "            mpa, m_iou, m_fw_iou = compute_metrics(segs, segs_pred)\n",
    "            mean_accuracy.append(mpa)\n",
    "            mean_iou.append(m_iou)\n",
    "            mean_fw_iou.append(m_fw_iou)\n",
    "\n",
    "        val_loss = float(running_loss) / len(val_loader)\n",
    "\n",
    "        wandb.log({\"Validation Loss\": val_loss,\n",
    "                   \"Validation Mean Pixel Acc\": np.mean(mean_accuracy),\n",
    "                   \"Validation Mean IoU\": np.mean(mean_iou),\n",
    "                   \"Validation Frequency Weighted IoU\": np.mean(mean_fw_iou)}, step=step)\n",
    "\n",
    "        wandb.log({\"Images Data\": table})\n",
    "\n",
    "        model_ckpt(model, epoch, np.mean(mean_iou))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96ed1fbe18e30cec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, config, device, epoch):\n",
    "    running_loss = 0.0\n",
    "    global step\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_loader, 0),\n",
    "                unit=' images',\n",
    "                unit_scale=config.batch_size,\n",
    "                total=len(train_loader),\n",
    "                smoothing=0,\n",
    "                disable=False)\n",
    "\n",
    "    for (batch_idx, data) in pbar:\n",
    "\n",
    "        imgs = data[\"image\"]\n",
    "        segs = data[\"seg\"]\n",
    "        imgs, segs = imgs.to(device), segs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        segs_pred = model(imgs)\n",
    "        loss = criterion(segs_pred, segs)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += float(loss)\n",
    "        step += len(imgs)\n",
    "        train_loss = float(running_loss) / (batch_idx + 1)\n",
    "        pbar.set_description(f'Training [ E {epoch}, L {loss}, L_Avg {train_loss}')\n",
    "\n",
    "        batch_idx += 1\n",
    "        if batch_idx % config.log_freq == 0:\n",
    "            wandb.log({\"Training Loss\": train_loss}, step=step)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74af0ed1c1b9968b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters=None):\n",
    "    with wandb.init(config=hyperparameters):\n",
    "        global step\n",
    "        step = 0\n",
    "        config = wandb.config\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        train_dataset = LFWDataset(download=True, base_folder='data/lfw_dataset', split_name=\"train\")\n",
    "        val_dataset = LFWDataset(download=False, base_folder='lfw_dataset', split_name=\"val\")\n",
    "        test_dataset = LFWDataset(download=False, base_folder='lfw_dataset', split_name=\"test\")\n",
    "\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=config.batch_size,\n",
    "                                  pin_memory=True,\n",
    "                                  shuffle=False,\n",
    "                                  sampler=None,\n",
    "                                  num_workers=0)\n",
    "\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=config.batch_size,\n",
    "                                pin_memory=True,\n",
    "                                shuffle=False,\n",
    "                                sampler=None,\n",
    "                                num_workers=0)\n",
    "\n",
    "        test_loader = DataLoader(test_dataset,\n",
    "                                 batch_size=config.batch_size,\n",
    "                                 pin_memory=True,\n",
    "                                 shuffle=False,\n",
    "                                 sampler=None,\n",
    "                                 num_workers=0)\n",
    "\n",
    "        model = UNet(n_channels=3, n_classes=3, bilinear=config.bilinear)\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        if config.optimizer == \"adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        elif config.optimizer == \"sgd\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "            \n",
    "        model_ckpt = ModelCheckpoint(0.0, True, 5, \"mean_iou\")\n",
    "        for epoch in range(config.epochs):\n",
    "            val(model, val_loader, criterion, config, device, epoch, model_ckpt)\n",
    "            train(model, train_loader, criterion, optimizer, config, device, epoch)\n",
    "\n",
    "        test(model, test_loader, device)\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5efeeaada48b70db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'Validation Loss', 'goal': 'minimize'},\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 0.1\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'distribution': 'q_log_uniform_values',\n",
    "            'q': 8,\n",
    "            'min': 8,\n",
    "            'max': 32,\n",
    "        },\n",
    "        'epochs': {'value': 30},\n",
    "        'classes': {'value': 3},\n",
    "        'log_freq': {'value': 10}\n",
    "\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"face-segmentation-sweeps-grid\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187eca6685079695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {'name': 'Validation Loss', 'goal': 'minimize'},\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.01, 0.001, 0.0005]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [16, 32]\n",
    "        },\n",
    "        'epochs': {'value': 30},\n",
    "        'classes': {'value': 3},\n",
    "        'log_freq': {'value': 10},\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'sgd']\n",
    "        }\n",
    "\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"face-segmentation-sweeps-grid\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99a0c020cfe9cf87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, model_pipeline, count=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73fa9321c93629da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = dict(\n",
    "        epochs=50,\n",
    "        classes=3,\n",
    "        batch_size=32,\n",
    "        learning_rate=0.0005,\n",
    "        dataset=\"LFW\",\n",
    "        architecture=\"UNet\",\n",
    "        log_freq=10,\n",
    "        optimizer=\"adam\")\n",
    "\n",
    "model_pipeline(config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b631588b848d4e1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
